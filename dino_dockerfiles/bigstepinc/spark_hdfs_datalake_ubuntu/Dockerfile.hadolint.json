[{"line":1,"code":"DL3006","message":"Always tag the version of an image explicitly","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":4,"code":"DL3003","message":"Use WORKDIR to switch to a directory","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":4,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":5,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":6,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":8,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":8,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":9,"code":"DL3008","message":"Pin versions in apt get install. Instead of `apt-get install <package>` use `apt-get install <package>=<version>`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":9,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":9,"code":"DL3015","message":"Avoid additional packages by specifying `--no-install-recommends`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":10,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":11,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":12,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":20,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":22,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":23,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":24,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":26,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":27,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":30,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":39,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":39,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":39,"code":"DL3003","message":"Use WORKDIR to switch to a directory","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":44,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":51,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":53,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":54,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":56,"code":"DL3042","message":"Avoid use of cache directory with pip. Use `pip install --no-cache-dir <package>`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":56,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":56,"code":"DL3013","message":"Pin versions in pip. Instead of `pip install <package>` use `pip install <package>==<version>` or `pip install --requirement <requirements file>`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":57,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":58,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":59,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":60,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":61,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":65,"code":"DL3042","message":"Avoid use of cache directory with pip. Use `pip install --no-cache-dir <package>`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":65,"code":"DL3013","message":"Pin versions in pip. Instead of `pip install <package>` use `pip install <package>==<version>` or `pip install --requirement <requirements file>`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":66,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":67,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":68,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":69,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":70,"code":"DL3042","message":"Avoid use of cache directory with pip. Use `pip install --no-cache-dir <package>`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":70,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":70,"code":"DL3013","message":"Pin versions in pip. Instead of `pip install <package>` use `pip install <package>==<version>` or `pip install --requirement <requirements file>`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":78,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":78,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":79,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":80,"code":"SC2039","message":"In POSIX sh, echo flags are undefined.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":80,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":84,"code":"DL3003","message":"Use WORKDIR to switch to a directory","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":93,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":95,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":96,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":100,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":100,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":100,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":102,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":103,"code":"SC2016","message":"Expressions don't expand in single quotes, use double quotes for that.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":103,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":108,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":109,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":111,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":114,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":114,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":114,"code":"DL3003","message":"Use WORKDIR to switch to a directory","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":128,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":128,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":129,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":129,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":129,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":130,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":130,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":130,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":134,"code":"DL3009","message":"Delete the apt-get lists after installing something","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":135,"code":"DL3015","message":"Avoid additional packages by specifying `--no-install-recommends`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":135,"code":"DL3008","message":"Pin versions in apt get install. Instead of `apt-get install <package>` use `apt-get install <package>=<version>`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":135,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":138,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":141,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":141,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":143,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":149,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":150,"code":"DL3003","message":"Use WORKDIR to switch to a directory","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":150,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":150,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":150,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":154,"code":"DL3004","message":"Do not use sudo as it leads to unpredictable behavior. Use a tool like gosu to enforce root","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":154,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":154,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":154,"code":"DL4006","message":"Set the SHELL option -o pipefail before RUN with a pipe in it. If you are using /bin/sh in an alpine image or if your shell is symlinked to busybox then consider explicitly setting your SHELL to /bin/ash, or disable this check","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":156,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":156,"code":"DL3009","message":"Delete the apt-get lists after installing something","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":157,"code":"DL3015","message":"Avoid additional packages by specifying `--no-install-recommends`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":157,"code":"DL3008","message":"Pin versions in apt get install. Instead of `apt-get install <package>` use `apt-get install <package>=<version>`","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":157,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":160,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":166,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":166,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":169,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":169,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":172,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":172,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":178,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":181,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"},{"line":183,"code":"DL3003","message":"Use WORKDIR to switch to a directory","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":183,"code":"DL4006","message":"Set the SHELL option -o pipefail before RUN with a pipe in it. If you are using /bin/sh in an alpine image or if your shell is symlinked to busybox then consider explicitly setting your SHELL to /bin/ash, or disable this check","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":183,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":183,"code":"SC2039","message":"In POSIX sh, echo flags are undefined.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":193,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":194,"code":"DL3059","message":"Multiple consecutive `RUN` instructions. Consider consolidation.","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":197,"code":"DL4001","message":"Either use Wget or Curl but not both","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"warning"},{"line":197,"code":"DL3047","message":"Avoid use of wget without progress bar. Use `wget --progress=dot:giga <url>`.Or consider using `-q` or `-nv` (shorthands for `--quiet` or `--no-verbose`).","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"info"},{"line":199,"code":"DL3020","message":"Use COPY instead of ADD for files and folders","column":1,"file":"/Users/vlad/Dev/itu/sem3/res_proj/dino_dockerfiles//bigstepinc/spark_hdfs_datalake_ubuntu/Dockerfile","level":"error"}]